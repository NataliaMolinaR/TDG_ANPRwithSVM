% !TeX spellcheck = es_ES
% !TeX encoding = ISO-8859-1


En el presente capítulo se describe el proceso de desarrollo del proyecto, donde se detallan los procedimientos llevados a cabo a fin de cumplir los objetivos planteados.


\section{Arquitectura de software}

El software se basó en una arquitectura estructural. Para cumplir la condición anterior, dado el problema que se desea resolver a través de un algoritmo, se divide dicho algoritmo en módulos siguiendo los principios de diseño de descomposición por refinamiento sucesivo, creación de jerarquía modular y elaboración de módulos independientes.

Los procesos descritos fueron diseñados para trabajar de forma modular e independientes, cada uno con una funcionalidad específica. Este proyecto se dividió en dos grandes módulos: procesamiento de imágenes y reconocimiento de caracteres. 

Se seleccionó esta arquitectura ya que la solución propuesta para la problemática planteada se puede describir en dos etapas diferentes, cuyas  funcionalidades son independientes entre sí, pudiéndose  definir las interacciones entre las entradas y salidas. En la Figura \ref{fig:tdgmodulos} se puede observar un esquema general del proyecto expresada en módulos.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth]{Imagenes/TDG_modulos}
	\caption{Módulos del sistema}
	\label{fig:tdgmodulos}
\end{figure}




\section{Componentes del sistema}

Se busca recrear de manera computarizada el proceso de observar una placa y leer su información. Por ello, se cuenta con una serie de herramientas y técnicas desarrolladas en Machine Learning y Visión Computarizada. El procesamiento de imágenes con OpenCV, el filtrado de la información y por último la SVM imitará el reconocimiento de caracteres, cumpliendo así con los objetivos planteados. 

Dado lo anterior, se necesitará: un computador dónde se ejecutará el algoritmo del proyecto y una base de datos compuesta por un conjunto de imágenes de caracteres que conformarán el conjunto de entrenamiento. Dado que el presente proyecto consiste en el diseño de software, no contempla la captura de escenas.   Las pruebas se realizarán con tomas previamente capturadas en condiciones controladas tanto en iluminación como en la posición del objeto. Con lo anterior expuesto, el único componente físico que se requiere es un  computador. 


\section{Computador.}

Este proyecto, al tratarse de un diseño de software, requiere únicamente de un computador con las capacidades de computo suficientes para manejar los procedimientos lógicos y matemáticos que componen al algoritmo. Por lo tanto, no es necesario el uso de equipos especializados para su desarrollo.

El computador es una máquina Toshiba Satellite C55 Series. El sistema operativo es Microsoft Windows 10. Las principales características del computador se describen en la Tabla \ref{Tab:computo}:



\begin{table}[H]
	\centering
	\caption{Especificaciones del computador Toshiba Satellite C55 Series}\label{Tab:computo}
	\medskip
	\begin{tabular}{llr}
		\toprule
		Alimentación &  19V \\

		Procesador & AMD QUAD-CORE A6 \\ 

		Memoria RAM & 16GB \\ 
		
		Tipo de sistema operativo & 64 bits \\ 
		\bottomrule
	\end{tabular}
\end{table}


\section{Base de datos}

En general, existen númerosas bases de datos de matrículas vehículares de diferentes países del mundo y estas incluyen fotos de la placa completa. Es por ello que no es posible emplearlas para el entrenamiento de la SVM tomando en cuenta los objetivos del presente proyecto. 

Para cumplir con los requerimientos planteados, es fundamental contar con una base de datos compuesta por imágenes de todas las letras y números del abecedario español individualmente que participen en la identificación de la matrícula. Es decir, cada imagen debe contener solo un tipo de carácter. Por lo tanto, para entrenar la SVM fue necesario construir dicha base de datos.

Se construyó una base de datos que cuenta con 1496 imágenes de caracteres de letras y números. Para su construcción se recopiló al menos 250 fotos de placas vehículares de origen Venezolano y se procesaron utilizando herramientas provistas por la librería OpenCV, a fin de obtener la información de interés. 

Las técnicas empleadas para su construcción se basan en la detección de contornos a partir de la umbralización de la imagen. Empleando diferentes funciones del procesamiento de imágenes y lógica condicional en la programación, se detectaron los caracteres de interés y se extrajeron recortando la foto. Las medidas adecuadas para su extracción se obtuvieron a partir de la medición del aspect ratio (Relación entre la altura y ancho del contorno rectangular) y el área ocupada por el carácter en la foto, conservando una distancia prudencial entre los bordes y el carácter . El resultado de la construcción resultó en imágenes de 25 x 45 px, en blanco y negro. 

El almacenamiento de cada uno de los ejemplos de entrenamiento se realizó en un archivo .csv, el cual permitió registrar en forma de matriz todos los ejemplos de entrenamiento. Para generar dicha matriz se redujo aún más el tamaño de la imagen que contiene cada muestra, resultado en una imagen de 27 x 15 px, lo cual se traduce en 405 pixeles por muestra. De esta forma, cada fila de la matriz contenida en el archivo .csv corresponde a un ejemplo de entrenamiento individual. La última columna de una fila corresponde a la etiqueta que identifica el carácter de esa imagen. Para la escritura de este archivo se empleó la librería csv provista por Python.

En el diseño, una de las mayores dificultades fue la construcción de la base de datos, ya que fue necesario  ajustar diferentes parámetros en el proceso de extracción de las muestras. Por otro lado, la adquisición de tantas placas Venezolanas representó una gran dificultad, dado que fue necesario tomar todas las fotos y no se disponía el acceso a tantas placas de manera inmediata o en la red. Es por esto, que se cuenta con un número limitado de ejemplos de entrenamiento en comparación a los números comunes, que por lo general superan el millón de muestras.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{Imagenes/data_base}
	\caption{Muestras de imágenes del conjunto de entrenamiento creado.}
	\label{fig:database}
\end{figure}

La cantidad de muestras  extraídas por cada clasificación se muestra en la Tabla \ref{Tab:tags}.


\begin{table}[H]
	\centering
	\caption{Clasificación y etiquetas de cada carácter.}\label{Tab:tags}
	\begin{adjustbox}{center, width=\columnwidth-10pt}  
		
	\begin{tabular}{llr}
		\toprule
		Clasificación & Etiqueta & Cantidad extraída \\ 
		\midrule
			0&0&46 \\
			
			1&1&43 \\
			
			2&2&71 \\
			
			3&3&54 \\
			
			4&4&66 \\
			
			5&5&50 \\
			
			6&6&72 \\
			
			7&7&65	\\
			
			8&8&58	\\
			
			9&9&70	\\
			
			A&10&297 \\
			
			B&11&65 \\
			
			C&12&38	\\
			
			D&13&51	\\
			
			E&14&37	\\
			
			F&15&43	\\
			
			G&16&52	\\
			
			H&17&26	\\
			
			I&18&18	\\
			
			J&19&10	\\
			
			K&20&28	\\
			
			L&21&13	\\
			
			M&22&46	\\
			
			N&23&16	\\
			
			Ñ&-&-	\\
			
			O&24&28	\\
			
			P&25&12	\\
			
			Q&26&0	\\
			
			R&27&18	\\
			
			S&28&8	\\
			
			T&29&5	\\
			
			U&30&13	\\
			
			V&31&23	\\
			
			W&32&13	\\
			
			X&33&18	\\
			
			Y&34&12	\\
			
			Z&35&7	\\
		\bottomrule
	\end{tabular}
\end{adjustbox}
\end{table}


\section{Software}

El proyecto tiene como objeto diseñar un sistema que permita el reconocimiento de la matrícula de un vehículo en una imagen estática, por lo tanto los videos no están contemplados en este diseño.

Dado que el objetivo es reconocer la información contenida en la matrícula de un vehículo, el software debe tener la capacidad de extraer los caracteres de interés contenidos en la placa mediante el procesamiento de imágenes y luego clasificar cada uno de ellos. 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth]{Imagenes/segmentacion}
	\caption{Proceso de segmentación de caracteres.}
	\label{fig:segmentacion}
\end{figure}


Para lograr lo anterior, se empleó  Python y la librería OpenCV de Intel.


Así, el software se divide en los siguientes tres módulos:

\begin{itemize}
	
	\item Detección de la placa través de técnicas de procesamiento de imágenes. 
	
	\item Segmentación de los caracteres mediante el procesamiento de imágenes.
	
	\item Clasificación de los caracteres empleando Machine Learning.
	
\end{itemize} 



\subsection{Detección de la placa}

El módulo de detección (ver Apéndice \ref{CAP:anexo1}) de la placa se define como un sistema dónde se ingresa una imagen frontal o posterior  de un vehículo y se obtiene la placa contenida. Se puede describir este proceso en las siguientes etapas:

\begin{itemize}
	
	\item Localización.
	
	\item Extracción.
	
\end{itemize}

De esta forma, es necesario emplear técnicas y herramientas que permitan detectar la localización de la placa mediante el procesamiento imagen. Se diseñó un procedimiento que sigue una serie de pasos con el fin de filtrar la información y detectar la placa en una captura de imagen. Para ello se emplearon funciones de la biblioteca OpenCV. Adicionalmente, se establecieron parámetros para la captura de imagen que dará entrada al sistema, las cuales se contemplan: distancia de 2 metros entre el vehículo y la cámara fotográfica, distancia de 1 metro de altura respecto al suelo y la cámara fotográfica, con el vehículo centrado en el medio del marco de captura  y tomar la fotografía con el flash activo. Se describe dicho proceso en el siguiente diagrama de flujo: 

\begin{figure}[H]
\centering
\includegraphics[width=0.85\linewidth]{Imagenes/diagramaDTPL}
\caption{Proceso de detección de la placa.}
\label{fig:diagramadtpl}
\end{figure}





 Así, se describe el procedimiento para la detección y extracción de la siguiente forma: 

\begin{enumerate}

\item \textbf{Suavizado de ruido}: En primer lugar, es necesario suavizar el ruido de la imagen que contiene la placa, limpiándola de características no deseadas. En la  placa, particularmente, se halla rodeada de mucho ruido debido que se encuentran muchos objetos alrededor del carro, por lo que es muy importante realizar este procedimiento. Para realizar esto se empleó con un núcleo gaussiano mediante la función \verb|cv2.GaussianBlur|.

\item \textbf{Redimensionamiento de imagen}: La imagen que contiene la placa es redimensionada para reducir el mapa de pixeles dónde se estima que estará la placa. Esto con el fin de facilitar el trabajo de la posterior detección de contornos. En las condiciones controladas presentadas se establece que el vehículo se debe encontrar en el medio del marco de captura, por lo que aproximadamente el 20\% de los laterales de la fotografía se considera ruido.  Así, se elimina el 20\% de los laterales y este redimensionamiento se logra empleando fundamentalmente la función \verb|cv2.rezise|. 


\item  \textbf{Umbralización}: La umbralización se realiza con el fin de binarizar la imagen. Para la detección de contornos es imprescindible que la binarización sea inversa. De esta forma, los contornos detectados se resaltan en blanco y el fondo en negro. En este proyecto se empleó la umbralización adaptativa \verb|cv2.adaptativetresholding|. La \textit{umbralización adaptativa} es una función que a partir de los parámetros ingresados binariza considerando pequeñas regiones de la imagen, a diferencia de una umbralización estandar. Por lo tanto, la umbralización adaptativa cálcula el valor umbral adecuado para cada región, mediante un núcleo gaussiano. La importancia de  su capacidad adaptativa radica en que factores externos como la variación de la iluminación pueden afectar significativamente el proceso de binarización.

\item  \textbf{Detección de contorno}: La detección de contornos se aplica sobre la imagen umbralizada, donde ya la mayoría del ruido ha sido filtrado. En este paso, se utilizó la función \verb|cv2.findcontours| la cuál retorna una variable que contiene los contornos detectados. La detección de los contornos en la imagen depende de los parámetros ingresados en la función. En este caso, se detectan los contornos cerrados en la imagen.

\item \textbf{Filtrado de contorno}: La filtración de contorno consiste en seleccionar los contornos de interés. Se empleó lógica condicional a fin de verificar si el contorno califica o no. Para ello, se estimó el área y el aspect ratio que ocupa un caracter dentro de la placa. Se ponderaron los valores de ancho y alto de varias muestras para obtener un valor umbral. Para obtener las coordenadas de los caracteres se utilizó la función \verb|cv2.boundingrectangle|, la cual permite encerrar en rectángulos los contornos detectados y devuelve los valores que permiten definir su posición en la imagen.

\item \textbf{Extracción de la placa}: Así, se extrajo recortando la imagen  con funciones básicas de Python, que consiste en extraer un segmento de la imagen a partir de las coordenadas indicadas. 


\end{enumerate}



\subsection{Segmentación de los caracteres.}


El módulo de segmentación (ver Apéndice \ref{CAP:anexo2}) se encarga de detectar, segmentar y extraer los caracteres de interés dentro de la placa. La secuencia de pasos a seguir en este módulo es muy similar al de módudulo anterior \textit{Detección de la placa}, pues se requiere un tratamiento para la extracción de cada caracter. Considerando lo anterior, se detallarán las diferencias de importancia.


Esto se realizó mediante técnicas de procesamiento de imágenes mediante la librería la librería OpenCV. Se describe  dicho proceso en el siguiente diagrama de flujo:

\begin{figure}[H]
	\centering
	\includegraphics[width=1\linewidth]{Imagenes/Segmentacion_caracter_diagrama}
	\caption{Procedimiento de segmentación de los caracteres de la matrícula.}
	\label{fig:segmentacioncaracterdiagrama}
\end{figure}


\begin{enumerate}
	
	
	\item \textbf{Suavizado de ruido:}  Con el fin de eliminar las características no deseadas en la placa  se emplea el suavizado de  ruido con un kernel gaussiano mediante la función \verb|cv2.GaussianBlur|.
	
	\item \textbf{Redimensionamiento de la imagen:} La imagen que contiene la placa es redimensionada hasta obtener 150px de altura, posteriormente permitirá que el algoritmo pueda detectar y extraer los caracteres en segmentos  de 25 x 45 px. En general, los ejemplos de entrenamiento son contenidos en imágenes de dimensiones pequeñas considerando que cada pixel que la compone es una característica de entrada para el algoritmo, lo cual significa un importante costo computacional. Para lograr el redimensionamiento se empleó fundamentalmente la función \verb|cv2.rezise|. 
	
	\item \textbf{Umbralización de la imagen:} Se binariza la imagen inversamente mediante la Umbralización adaptativa empleando un núcleo Gaussiano y se implementa utilizando la función \verb|cv2.adaptativetresholding|. 
	
	\item \textbf{Detección de contorno:} Se detectan los contornos cerrados de la imagen binarizada mediante la función \verb|cv2.findcontours| la cuál retorna una variable que contiene los contornos detectados. 
	
	\item \textbf{Filtración de contornos:} Empleando la lógica condicional se filtran los contornos de interés en la imagen binarizada. Para ello, se estimó el área y el aspect ratio que ocupa un caracter dentro de la placa. Se ponderaron los valores de ancho y alto de varias muestras para obtener un valor umbral. Así, se definió una relación porcentual del área del carácter respecto al área de la placa y un bias que permita cubrir la mayoría de las variaciones. Para obtener las coordenadas de los caracteres se utilizó la función \verb|cv2.boundingrectangle|, la cual permite encerrar en rectángulos los contornos detectados y devuelve los valores que permiten definir su posición en la imagen.
	
	\item \textbf{Recorte de los caracteres:} Con las coordenadas de los caracteres, se  recortaron de la imagen con un margen de provisión adecuado. Así, se aseguró contener completamente cada caracter en un segmento. Para la recortar la imagen se usaron las funciones básicas de Python, que consiste en extraer un segmento de la imagen a partir de unas coordenadas dadas. Así mismo, los caracteres son ordenados mediante la función sorted de Python, empleando una Key a través del cual se logran ordenar de izquierda a derecha.
	
	\item \textbf{Escritura en computador de los caracteres:} Una vez obtenido todos los segmentos se escriben en el computador utilizando \verb|cv2.imwrite|, con formato .jpg.
	
	
	
\end{enumerate}


\subsection{Clasificación de caracteres.}
 
 La etapa de clasificación de caracteres se lleva a cabo mediante el modelo entrenado.  En el Capitulo \ref{CAP:teor} en la Sección \ref{CAP:ML}  se describió como se puede obtener una etiqueta a partir de los parámetros obtenidos y la nueva observación. Esta etiqueta es la predicción de clase para la imagen de entrada que se está clasificando. En conclusión, este módulo se encarga de predecir la clasificación de cada nuevo carácter en base al modelo obtenido del entrenamiento (ver apéndice \ref{CAP:anexo4} en el Anexo).
 
 El clasificador es un método para determinar la clase más probable de una entrada desconocida con respecto a un número de ejemplos de todas las clases. Este conjunto de ejemplos se denomina conjunto de entrenamiento. 
 
 El primer paso en el proceso de clasificación es la extracción de características de una entrada, esto se traduce en expresar cada instancia u objeto como un vector de medidas. Cuando las imágenes están siendo clasificadas, usualmente el vector es extraído a partir de las intensidades de los píxeles. Generalmente se lleva a cabo un paso de reducción de características, ya que disminuye los costos computacionales. Es importante considerar que la reducción no debe provocar una pérdida significativa de la información. Las medidas obtenidas son denominadas características y pueden ser reales, enteras o categóricas. 
 
 Una vez extraídas las características se introducen al algoritmo clasificador el cuál trabaja en dos naturalezas distintas: supervisado o no supervisado. En este proyecto se utilizará la clasificación supervisada, ya que se conoce la relación entre la entrada y la salida. En la clasificación supervisada, durante el entrenamiento conocemos la entrada y cuál debería ser su clasificación. En la clasificación no supervisada no se conoce la relación entre la entrada y la salida. 
 
 Para la extracción de características se  emplearon las diferentes herramientas de manejo de matrices  que ofrece Python para convertir esa entrada en un vector plano que pudiera leer el algoritmo de clasificación. En el  Figura \ref{fig:procesodeclasificaicon} se puede observar  el diagrama del proceso de clasificación.
 
 \begin{figure}[H]
 	\centering
 	\includegraphics[width=0.7\linewidth]{Imagenes/procesodeclasificaicon}
 	\caption{Diagrama de proceso de clasificación }
 	\label{fig:procesodeclasificaicon}
 \end{figure}
 


\section{Módulo de entrenamiento}

Dado un conjunto de muestras, se etiquetan las clases a manera de construir un modelo con la capacidad de predecir una nueva entrada desconocida. En este caso, el modelo debe tener la capacidad de distinguir entre 36 clases diferentes, entre las cuales se encuentran las letras del abecedario español (excluyendo la Ñ) y los números del 0 al 1. En la Tabla \ref{Tab:tags} se puede observar cada etiqueta o clase asignada para cada carácter. 

De esta forma, se lleva a cabo el entrenamiento de la SVM utilizando un núcleo Lineal empleando las herramientas proporcionadas por la librería SKlearn SVM. El entrenamiento de una SVM consiste en encontrar los parámetros que generan el híperplano que cumplen con el máximo margen de separación entre las clases. Para la multiclasifidora se empleó la función de decisión \texttt{ovr} el cuál consiste en que cada clase se enfrenta hacia el resto de las clases para encontrar el híperplano que mejor las separa. 

El modelo obtenido es el resultado de ajustar los parámetros para todos los ejemplos de entrenamiento que conforman la base de datos. Cada ejemplo de entrenamiento representa una fila de la matriz que conforma la base de datos. Así, cada fila está compuesta por las características de la imagen  y su etiqueta. Este modelo es el utilizado para la clasificación de caracteres, el módulo final del proyecto. 

Así,  el módulo de entrenamiento se encarga de encontrar el modelo que mejor se ajusta a la base de datos proporcionada. El desempeño de este modelo es evaluado en la etapa de validación. 


\newpage

