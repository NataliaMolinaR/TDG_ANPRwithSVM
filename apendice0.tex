% !TeX spellcheck = es_ES
% !TeX encoding = ISO-8859-1

\begin{programa}{Módulo principal: ANPPR}{ANPR}
	import detecting_plate as dp
	import Extraction as et
	import PPIF as pf
	import joblib
	import cv2
	from time import time
	
	
	def character2str(character, plate_len, index):
	"""This function transform the ID character to string text"""
	
	int_character = character.astype(int)[0]
	
	if plate_len == 7:              # NEW PLATES
	
	if int_character < 10:      # Numbers
	str_character = str(int_character)
	
	else:                       # Letters
	str_character = chr(int_character + 55)
	print('caracter', character, str_character)
	
	if plate_len == 6:              # OLD PLATES
	
	if int_character < 10:      # Numbers
	str_character = str(int_character)
	
	if int_character == 0 and not (index == 4 or index == 5):
	str_character = 'O'
	
	else:                       # Letters
	if int_character == 24 and (index == 4 or index == 5):
	str_character = '0'
	else:
	str_character = chr(int_character + 55)
	print('caracter', character, str_character)
	
	return str_character
	
	
	def call_image():
	""" This function call the image that will be used for recognition"""
	
	file = './muestras/carro_10.jpg'
	src = cv2.imread(file)
	name_number = pf.calculting_name()
	return src, name_number
	
	
	def run():
	
	pis_time = time()
	image, name_number = call_image()
	plate = dp.detecting_plate(image, name_number)
	characters = et.extraction(plate)
	pif_time = time()
	svm_recon = joblib.load('modelo_entrenado1.pkl')
	plate_str = ''
	index = 1
	plate_len = len(characters)
	
	rs_time = time()
	for segment in characters:
	
	data = segment.reshape(-1)
	character = svm_recon.predict([data])
	str_character = character2str(character, plate_len, index)
	plate_str += str_character
	rf_time = time()
	
	for i in range(0, len(characters)): #Showing the character extraction results
	graf, _ = pf.resizing(plate, plate, 150)
	cv2.imshow('Plate', graf)
	cv2.imshow('Character' + str(i), characters[i])
	cv2.moveWindow('Character' + str(i), 20 + i * 120, 250)
	index += 1
	
	pif_time = round(pif_time - pis_time, 3)
	r_time = round(rf_time - rs_time, 3)
	print('Tiempo de procesamiento de imagen: '+ str(pif_time))
	print('Tiempo de reconocimiento de caracteres: ' +str(r_time))
	
	print('La placa es:', plate_str)
	cv2.waitKey(0)
	cv2.destroyAllWindows()
	
	
	if __name__ == '__main__':
	run()
\end{programa}

\begin{programa}{Módulo detección de placa}{DTP}
	
	import cv2
	import PIF as pif
	
	
	def detecting_plate(imagen, number_car):
	
	plate = []
	num_file = number_car
	
	plate_detected = False
	cv2.destroyAllWindows()
	
	src = imagen
	
	cut_src = pif.resizing_image(src)
	
	s_noise = pif.softing_noise(cut_src, 5)
	
	thresh_image, _ = pif.threshold_image(s_noise)
	
	contour = pif.finding_contours(thresh_image)
	
	for c in contour:  # FIRST CASE SEARCHING THE PLATE RECTANGLE
	
	plate_detected, plate = pif.searching_plate(contour, cut_src, plate_detected, num_file)
	break
	
	for kn in [3, 5, 7]:         # SECOND CASE: THE IMAGE CONTOURS ARE EXPANDED TO FIND THE PLATE
	
	dilation = pif.dilating_image(thresh_image, kn, 1)
	
	contour_dilated = pif.finding_contours(dilation)
	
	for c in contour_dilated:
	
	x, y, w, h = cv2.boundingRect(c)
	
	plate_detected, plate = pif.searching_plate(contour_dilated, cut_src, plate_detected, num_file)
	break
	
	if plate_detected:
	break
	
	if not plate_detected:                     # THIRD CASE: REMOVE THE NOISE SMOOTHING AND DILATING TO SEARCH THE PLATE
	
	thresh_image, _ = pif.threshold_image(cut_src)
	contour = pif.finding_contours(thresh_image)
	
	for c in contour:
	x, y, w, h = cv2.boundingRect(c)
	
	plate_detected, plate = pif.searching_plate(contour, cut_src, plate_detected, num_file)
	print('Tercer caso')
	break
	
	return plate

\end{programa}

\newpage



\begin{programa}{Librería pre procesamiento de imágenes para la detección de placa}{PIF}
	
import cv2
import numpy as np

""" This library is used for the plate detection and extraction"""


def resizing_image(image):
"""It Reading image's dimensions which going to be resizing and proper cutting  it. Whether you want change the size
of the picture you have to change te width_new parameter. At the bottom of this function are a little code where you
might check all values"""

height, width = image.shape[0:2]

aspect_ratio = (width / height)

width_new = 1350

height_new = int(round(width_new / aspect_ratio))

standard_src = cv2.resize(image, (width_new, height_new))

start_x = int(height_new * .45)
final_x = int(height_new * .85)

start_y = int(width_new * 0.20)
final_y = int(width_new * 0.85)

cut_src = standard_src[start_y:final_y, start_x:final_x]

"""print('Height =' + str(height), 'Width =' + str(width), 'Height new =' + str(height_new),
'Width new =' + str(width_new),'Start_x =' + str(start_x), 'Final_x' + str(final_x), 
'Start_y =' + str(start_y), 'Final_y' + str(final_y))"""

return cut_src


def softing_noise(image, kn):
""" It Softing the noise in the original image. kn  is the dimension  of the Kernel.I recommend you to use kn=5 for
majority of pictures """

s_noise = cv2.GaussianBlur(image, (kn, kn), 0)

return s_noise


def threshold_image(image):
"""Converting to gray scale the image to make an adaptative thresholding for find the outlines"""

gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

thresh_image = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 13)

return thresh_image, gray


def dilating_image(image, kn, i):
"""Dilating image's contours. kn is the dimensions of kernel"""

kernel_dlt = np.ones((kn, kn), np.uint8)

dilation = cv2.dilate(image, kernel_dlt, i)

return dilation


def finding_contours(image):
"""Searching in the image's contour"""

contour, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

return contour


def searching_plate(contour, image_print, plate_detected, number_file):
"""This function compare all the contours had found width and height with average values in order to filter them"""

global plate

width_max_plate = 190
width_min_plate = 160
height_max_plate = 95
height_min_plate = 70

for c in contour:
x, y, w, h = cv2.boundingRect(c)

if (w <= width_max_plate) and (w >= width_min_plate) and (h <= height_max_plate) and (h >= height_min_plate):  # FILTERING THE RECTANGLE'S HEIGHT

image_plate = cv2.rectangle(image_print, (x, y), (x + w, y + h), (0, 255, 0), 2)  #DRAWING THE PLATE'S RECTANGLE
plate_detected = True

plate = image_print[y:y+h, x:x+w]

# cv2.imshow('Plate ' + number_file, plate)
# cv2.moveWindow('Plate ' + number_file, 30, 20)

# cv2.imshow('Plate detected number  ' + number_file, image_plate)
# cv2.moveWindow('Plate detected number  ' + number_file, 950, 20)

if not plate_detected:
plate = None

return plate_detected, plate

\end{programa}

\newpage

\begin{programa}{Módulo extracción de caracteres}{ETC}
	import PPIF as pf
	import cv2
	
	
	def extraction(source):
	
	for n_char in [7, 6]:
	for kn_blr in [11, 15, 9, 1]:
	
	no_noise = pf.softing_noise(source, kn_blr)
	resize, image_tocut = pf.resizing(no_noise, source, 150)
	to_detect, to_cut = pf.threshold_image(resize)
	contour, _ = cv2.findContours(to_detect, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
	detecting, character = pf.detecting_characters(contour, resize, _)
	
	if len(character) == n_char:
	break
	if not len(character) == n_char:
	continue
	
	break
	
	character = pf.org_character(character)
	to_cut = pf.preparing_tocut(image_tocut)
	segmented = pf.cutting_characters(character, to_cut)
	
	return segmented
	
	if __name__ == '__main__':
	extraction()
	
\end{programa}

\newpage

\begin{programa}{Librería pre procesamiento de imágenes para la detección de caracteres}{PPIF}
	
import cv2
import numpy as np
import os
import glob

""" This library is used for the character detection and extraction"""

def calculting_name():
""" This function search ID number of the image that contains a plate number"""

list_of_files = glob.glob('./muestras/*') # * means all if need specific format then *.csv
latest_file = max(list_of_files, key=os.path.getctime)
_, name_file = os.path.split(latest_file)
name, _ = os.path.splitext(name_file)
name_number = str(name)

return name_number


def resizing(image, image_2, desire_width):
"""This function Resize the image in width and height using original aspect ratio. It use desire width for calculate the new height

Besides, resizing returns the same image twice because the extraction module needs it for later image processing purposes."""

height, width = image.shape[0:2]

aspect_ratio = (width / height)

new_width = desire_width

new_height = int(round(new_width / aspect_ratio))

standard_src = cv2.resize(image, (new_width, new_height))

image_tocut = cv2.resize(image_2,(new_width, new_height))

return standard_src, image_tocut

def softing_noise(image, kn):
""" It Softing the noise in the original image. kn  is the dimension  of the Kernel.I recommend you to use kn=5 for
majority of pictures """

s_noise = cv2.GaussianBlur(image, (kn, kn), 0)

return s_noise


def threshold_image(image):
"""Converting to gray scale the image to make an adaptative thresholding for find the outlines"""

gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

thresh_image_inv = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 7)

thresh_image = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 7)
return thresh_image_inv, thresh_image


def dilating_image(image, kn, i):
"""Dilating image's contours. kn is the dimensions of kernel"""

kernel_dlt = np.ones((kn, kn), np.uint8)

dilation = cv2.dilate(image, kernel_dlt, i)

return dilation




def estimation_area(image, width, height):
""" This functions develops differents  area estimation that will be uses in the caracter detection

There is particular characters that are out of common average:

Common average: w 17 - h 35.
One: w 7 - h 35.
I: w 10 - h 35.

This occurs by the way that Boundingrectangle works.

"""

area = width * height
height_w, width_w = image.shape[0:2]
whole_area = height_w * width_w
relation_area = area / whole_area

area_character = relation_area
bias = area_character * 0.50
low_limit = area_character - bias
high_limit = area_character + bias

aspect_ratio = width / height
aspect_bias = aspect_ratio * 0.25
max_aspect = aspect_ratio + aspect_bias
min_aspect = aspect_ratio - aspect_bias

return low_limit, high_limit, max_aspect, min_aspect, whole_area


def detecting_characters(contour, image_print, number_file):
"""This function compare all the contours  values had found  with area_estimation values in order to filter them """
character = []
image = image_print.copy()
widths = [17, 10]

for w in widths:
low_limit, high_limit, max_aspect, min_aspect, whole_area = estimation_area(image_print, w, 35)
for c in contour:
x, y, w, h = cv2.boundingRect(c)
area_contour = w * h
aspect_ratio = w / h

if (area_contour/whole_area >= low_limit) and (area_contour/whole_area <= high_limit) and (aspect_ratio < max_aspect) and (aspect_ratio > min_aspect):
cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)  # DRAWING THE PLATE'S RECTANGLE

# print(w, h)
# cv2.imshow('Drawing', image)
# cv2.waitKey(0)

rectangle_char = (x, y, w, h)                   # x = UPPER - LEFT CORNER OF THESE RECTANGLE
character.append(rectangle_char)                # FILLING THE CHARACTER VARIABLE.


image_plate_char = image

return image_plate_char, character


def filling_white(image, smaller_image):
""" This functions set white the pixels according to percents that it has asigned """

rec_char_outer = image.copy()

fil_out, col_out = rec_char_outer.shape[0:2]

left_limit = 4
right_limit = col_out * 0.80
up_limit = 5
down_limit = fil_out * 0.95

for n in range(0, fil_out):
for m in range(0, col_out):
if ((m < left_limit) or (m > right_limit)) or ((n < up_limit) or (n > down_limit)):
rec_char_outer[n, m] = 255

return rec_char_outer


def key_ordenation(tupla):
""" This key indicates that it will be sort by the fisrt tupla's element. This element is the upper left x coordinate of the rectangle."""

return tupla[0]


def org_character(characters):
""" This functions will sort the characters have found left to right using the key ordenation"""

ord_characters = sorted(characters, key=key_ordenation)
return ord_characters


def cutting_characters(character, image_2cut):
""" In this functions develops the rectangles cut that contains every single character detected by using
the coordinates given by  BoundingRectangle function"""

preparing = []
m = len(character)
image_2cut = image_2cut.copy()

for n in character:

# The information is extracted from the the tupla n in character list.
# For more information about this coordinates check the Bounding Rectangle function resources
ulc_X = n[0]
ulc_Y = n[1]

width = n[2]
height = n[3]

#There is asigned new name to the above information and is constructed the rectangle.
start_x = int(ulc_X)
start_y = int(ulc_Y)

width_new = int(width)
height_new = int(height)


final_x = start_x + width_new
final_y = start_y + height_new

# A width and height outter value is placed  that allow a prudential margin of the principal content.
width_outer = 25
height_outer = 45


#Then the rectangle is constructed with these outter width and heigt and the x and y coordinate are displaced too.
x_outer = int(ulc_X) - 4
y_outer = int(ulc_Y) - 6

outer_xf = x_outer + width_outer
outer_yf = y_outer + height_outer

# Both rectangles are cutted by image_2cut

rec_char_outer = image_2cut[y_outer:outer_yf, x_outer:outer_xf]

rec_char_inter = image_2cut[start_y:final_y, start_x: final_x]

# Imperfections are corrected and filling with white color by filling_white

prep = filling_white(rec_char_outer, rec_char_inter)

prep, _= resizing(prep, prep, 15)

preparing.append(prep)

return preparing


def preparing_tocut(image):
""" This function  makes the treshhold in the entry image but use the non inverted treshold considering subsequent recognition processes"""

_, image = threshold_image(image)

return image
	
\end{programa}




