% !TeX spellcheck = es_ES
% !TeX encoding = ISO-8859-1




Para el desarrollo de este trabajo, es necesario manejar conceptos básicos de procesamiento de imagen y aprendizaje de máquina. 

\section{Imagen digital}

Una imagen se define, en este contexto, como la representación visual de un objeto real a través de técnicas como la fotografía, la pintura, el video, entre otras técnicas. Entonces, una imagen digital puede ser definida como una función bidimensional $f(x,y)$, dónde $(x,y)$  son coordenadas espaciales y f es la intensidad de la imagen en ese punto. Las imágenes digitales están compuestas por un número finito de elementos llamados pixel. Las imágenes digitales  dependiendo de si es dinámica o estática se pueden clasificar en dos tipos: imagen matricial o gráfico vectorial. 


El gráfico vectorial o la imagen vectorial, es una imagen digital formada por entidades geométricas independientes (segmentos, polígonos, arcos, entre otros), cada uno de ellos definidos por fórmulas matemáticas. Se construyen a partir de vectores y no se dividen en unidades mínimas de información como los pixeles, sino en manchas de color y lineas \cite{Alonso2018} . 

Por otro lado, la imagen matricial o mapa de bits es una estructura  que representa una rejilla rectangular  compuesta de pixeles o puntos de color. Estos, se suelen definir por su altura y grosor (en pixeles) por su profundidad de color. Esto determina el número de colores distintos que se pueden almacenar en cada punto individual. La calidad de las imagenes rasterizadas está definida por el total de pixeles que posee (Resolución) y la cantidad de información por pixel (Profunidad de color, bits por pixel). \cite{Alegsa2010}

Los pixeles guardan información de color en un determinado punto, es decir, una representación numérica de color y esta se ve limitada por la cantidad de bits utilizados para representarla, esto se conoce como profunidad de color. Normalmente, cada pixel es representado por tres valores numéricos. 

\section{Espacios de color}

El espacio de color define un modelo de composición de color. Por lo general, un espacio de color se compone de N vectores cuya combinación lineal puede generar todo el espacio de color.  Generalmente, lo espacios de color intentan representar todos los colores que el ojo humano puede percibir, mientras que otros aislan un subconjunto específico de colores. Los espacios de color pueden ser: una dimensión (Escala de grieses), dos dimensiones (RGB, CIEXYZ, CIELAB, YIQ) o  cuatro dimensiones (CMYK). Los espacios de color de tres dimensiones son, normalmente, los más usados. Es decir, un color se especifica usando tres coordenadas; la cual determina su ubicación en este espacio. 



\section{Procesamiento de imágenes digitales}



Se define así al conjunto de técnicas y métodos desarrollados para manipular la información contenida en una imagen digital. Estos consisten en aplicar diferentes operadores a la imagen con los siguientes objetivos \cite{ImageProcess}:

\begin{itemize}
	
	\item Restauración de la imagen: mejorar la calidad de la imagen de forma objetiva, como lo es reducir el ruido.
	
	\item Mejoramiento de la imagen: mejorar la calidad de la imagen de forma subjetiva, como incrementar el contraste, crear distorsión, entre otros.
	
	\item Compresión de la imagen: consiste en representar la imagen con la menor cantidad de bits posible, sin  afectar críticamente la calidad de la imagen, como lo es la reducción de dimensión, la binarización, entre otros.
	
	\item Extracción de objetos: resaltar explícitamente algunas características en la imagen que permitan la detección de objetos, tales como la  utilización de algoritmos para detección  y reconocimiento de contornos.
	
	
\end{itemize}

\subsection{Mascaras derivativas discretas}

El proceso de filtrado de una imagen se realiza mediante la convolución entre los distintos pixeles que componen la imagen y una matriz de convolución. Esta matriz es denominada "kernel" del filtro. Dependiendo de los valores que componen al kernel y su distribución se obtienen diferentes resultados de filtrado en la imagen. Las mascaras derivativas discretas no son más que Kernels cuyos elementos representan una aproximación de la derivada \cite{MaskDev}. En la figura \ref{fig:convolucionsobreunaimagen} se puede apreciar el proceso de convolución sobre un pixel.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{Imagenes/convolucionsobreunaimagen}
	\caption{Operación de convolución sobre un pixel}
	\label{fig:convolucionsobreunaimagen}
\end{figure}

Las mascaras derivativas son utilizadas para calcular el gradiente de una imagen, normalmente con la intención de detectar los contornos. Entre los más utilizados se encuentran: Sobel, Prewitt, Roberts y Laplaciano  \cite{Operadores}. En la figura \ref{fig:derivadassobel} se muestra el efecto obtenido después de aplicar el operador de Sobel en una imagen. 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{Imagenes/Derivadas_Sobel}
	\caption{Operador Sobel}
	\label{fig:derivadassobel}
\end{figure}

Bibliotecas de software libre orientadas hacia la visión computarizada como OpenCv, ofrecen funciones que utilizan estos operadores para determinar el gradiente de la imagen y así detectar los contornos mediante la umbralización:

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{Imagenes/grisesvsadapt}
	\caption{Umbralización adaptativa de librería OpenCV}
	\label{fig:grisesvsadapt}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{Imagenes/sobelvsumbral}
	\caption{Filtro de sobel vs Umbralización adaptativa}
	\label{fig:sobelvsumbral}
\end{figure}

Existen otras funciones especializadas en la detección de contornos como lo es Canny de OpenCV:

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{Imagenes/cannyvsumbral}
	\caption{Función Canny vs Umbralización adaptativa}
	\label{fig:cannyvsumbral}
\end{figure}




\subsection{Binarización}



Es una técnica que consiste en la realización de un barrido en la matriz de la imagen digital, por medio de
bucles o recursividad, con el fin de que el proceso produzca la reducción de la escala de grises a dos únicos valores. Negro(= 0) y blanco (= 255), o lo que es lo mismo, un sistema binario de ausencia y presencia de color 0-1. La comparación de cada píxel de la imagen viene determinada por el umbral de
sensibilidad (valor T = Threshold). Por ejemplo, los valores que sean mayores que el umbral toman un valor 255 (blanco) y los menores 0 (negro). 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\linewidth]{Imagenes/umbralizacion}
	\caption{Imagen a color binarizada.}
	\label{fig:umbralizacion}
\end{figure}




En base a las particularidades entre algoritmos categorizan los métodos de umbralización en seis grupos. Aquí añadimos uno más, los métodos globales \cite{Binarizacion}:
\begin{itemize}
	
	\item Histograma: métodos basados en el análisis de los picos
	máximos y mínimos de las curvas del histograma del suavizado de la imagen.
	
	\item Clustering: métodos basados en discernir como las muestras
	de los niveles de gris se agrupan o alternativamente se modelan como una mezcla de dos gaussianas.
	
	\item Entropía: métodos basados en el análisis de los resultados de
	la aplicación de algoritmos que utilizan la entropía de las
	regiones frontal y de fondo, la entropía cruzada entre la imagen original y binarizada.
	
	\item Similitud: métodos basados en la búsqueda de una similitud
	entre las escalas de grises, como la tonalidad difusa, los bordes de la imagen, etc.
	
	\item Espaciales: métodos analíticos que usan el orden de distribución, la probabilidad y/o la correlación entre los diferentes
	píxeles.
	
	\item Globales: métodos cuyo valor del umbral es estático.
	
	\item Locales: métodos que adaptan el valor del umbral, de forma
	manual o automática, a cada píxel dependiendo
	
\end{itemize}


\section{Máquina de Soporte Vectorial}

 Se define la Máquina de Soporte Vectorial (SVM por sus siglas en inglés) como  modelos  de aprendizaje supervisado que implementa la idea de mapear el vector de entrada en un espacio de características Z de gran dimensión mediante un mapeo no lineal. En este espacio una superficie lineal es construída con propiedades que aseguran una alta capacidad de generalización. Este tipo de algoritmo es usualmente utilizado en el reconocimiento de patrones, aunque también puede desempeñarse en regresión lineal.

Los problemas de clasificación en su forma más básica consiste en separar dos grupos o clases, estos son llamados problemas de clasificación binaria. Muchos problemas de clasificación pueden ser resueltos por las máquinas si los grupos son linealmente separables. Al ser linealmente separables es posible encontrar un hiperplano que divida las clases. De lo contrario, es necesario utilizar máquinas no lineales o llevar a cabo transformaciones que permitan separar los datos.

Construir el modelo o hipótesis del algoritmo SVM supone encontrar los parámetros del hiperplano que mejor separe $x_i \in R^m$ para $i=1,2,...,n$ elementos en dos grupos o clases de datos. Existen infinitos hiperplanos que separan un conjunto de datos, sin embargo, esto no asegura una buena generalización. 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.49\linewidth]{Imagenes/hiperplano}
	\caption{Un hiperplano que separa los datos en dos grupos.}
	\label{fig:hiperplan}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.49\linewidth]{Imagenes/varios_hiperplanos}
	\caption{Otros ejemplos de hiperplano que separan los datos en dos grupos.}
	\label{fig:hiperplano}
\end{figure}



El problema anterior es resuelto por el hiperplano óptimo de clases separables. El hiperplano óptimo es definido por la función de decisión lineal con máximo margen entre los vectores de dos clases. 
La propiedad fundamental del híperplano  de separación óptimo es que este equidista  del ejemplo más cerca de cada clase \cite{SVN}. Esta propiedad se refleja en la siguiente figura:

\begin{figure}[H]
	\centering
	\includegraphics[width=0.50\linewidth]{Imagenes/maximomargen}
	\caption{Hiperplano óptimo: máximo margen de separación entre dos clases.}
	\label{fig:maximomargen}
\end{figure}


Dado un set de entrenamiento clasificado: $$ (x_1,y_1),(x_2,y_2),...,(x_m,y_m),  \hspace{0.7cm} y_m \hspace{0.1cm}  \in \hspace{0.1cm} \left\lbrace  1,-1\right\rbrace$$

Se dice que son linealmente separables si existe un vector $w$ y un escalar $w_0$ que satisfaga la siguientes inecuaciones para todo el set de entrenamiento:

\begin{equation}	
\begin{split}
w^t \cdot x_i + w_0  1, \hspace{0.5cm} 	Si \hspace{0.2cm} y_i = 1 \\
w^t \cdot x_i + w_0 -1, \hspace{0.5cm} 	Si \hspace{0.2cm}  y_i = -1
\end{split}	
\label{condiciones}
\end{equation}



Dónde $w$ es el vector de pesos que ajusta el modelo, $w_0$ es un escalar también conocido como sesgo y x es el vector de datos de entrada a clasificar.

De esta forma, ajustar el modelo para el algoritmo se traduce en encontrar el hiperplano óptimo mediante el vector de pesos. El hiperplano óptimo se puede escribir entonces cómo:

\begin{equation}	
w^t \cdot x_i + w_0 = 0
\end{equation}


Es el único que separa el conjunto de entrenamiento con el máximo margen, el cual determina la dirección  $ w / |w|$ dónde la distancia entre las proyecciones de los vectores de entrenamiento  de dos clases es máxima.  Esta distancia es definida cómo:

\begin{equation}
\gamma = \frac{1}{\|  w^2 \|} 
\end{equation}



Entonces el problema se traduce en máximar $\gamma$ para encontrar dicho híperplano de separación óptimo tomando en cuenta las condiciones de las ecuaciones (\ref{condiciones}).

%%Las funciones de kernel permiten el uso eficiente de los espacios de características de grandes dimensiones.  La elección de utilizar una sesgo de aprendizaje convexo  resulta en la ausencia de mínimos locales, por lo tanto, las soluciones siempre pueden ser encontradas eficientemente incluso para conjuntos  de entrenamiento con  cientos de miles de ejemplos. Mientras que, la compacta representación de la hipótesis se traduce en evaluaciones rápidas de nuevas entradas. En consecuencia, los problemas de eficiencia del entrenamiento, eficiencia de prueba y comprobación, sobreajuste y ajuste de parámetros en el algoritmo son evitados por la SVM. 

El objetivo de la SVM es idear un método de aprendizaje computacionalmente eficiente. Los hiperplanos optimizan el límite de generalización, por lo tanto el algoritmo es capaz de manejar grandes dimensiones.\cite{SVM2014}

Algunas de las ventajas de las SVMs frente otros algoritmos son \cite{Sklearn}:

\begin{itemize}
	
	\item Efectividad en espacios de grandes dimensiones.
	
	\item Sigue siendo efectivo incluso en casos donde el número de dimensiones es más grande que el número de ejemplos de entrenamiento. 
	
	\item Usa un subconjuto de los ejemplos de entrenamiento en la función de decisión (Llamados vectores de soporte) por lo tanto es eficiente computacionalmente, en especial en el uso de la memoria.
	
	\item Es versátil: diferentes funciones de Kernel pueden ser especificadas para la función de decisión. Kernels comunes son proveídos pero es posible personalizarlos. 
	
\end{itemize}



\section{Lenguaje de programación Python }

Python es un lenguaje de programación multiparadigma, multiplataforma, dinámico e interpretado, es decir, se ejecuta directamente mediante un intérprete dejando a un lado la compilación. Actualmente, Python es  administrado por Python Software Foundation. El software posee una licencia de código abierto denominada Python Software Fondation License.


Python 3 se caracteriza por su amplia aplicabilidad en diferentes campos del desarrollo de nuevas tecnologías como lo es el Machine Learning, Data Science, Vision por Computador, entre otros. Python soporta diferentes librerías como  OpenCV  y Scikit-Learn, las cuales cuentan con extensa documentación acerca de sus aplicaciones e implementaciones. 

\section{OpenCV}

Open Computer Vision (OpenCV, por sus siglás en inglés) es una librería libre de visión artificial desarrollada originalmente por Intel. Especializada en la visión por computador y el procesamiento de imágenes cuenta con diferentes herramientas que permiten manipular la información dentro de una imagen. Para mayor información visitar  https://opencv.org/.


Entre las funciones que ofrece:

\begin{itemize}
	
	\item \verb|cv2.imread|: permite llamar una imagen digital al ambiente de desarrollo empleado para así poder manipularla mediante todas las otras herramientas que ofrece la librería. \cite{imread}
	
	
	\item \verb|img.shape|: lee y devuelve las dimensiones de una imagen digital en función del ancho y alto. \cite{imgshape}
	
	\item \verb|cv2.resize|: redimensiona el ancho y alto de una imagen de acuerdo a los parámetros de entrada especificados.  \cite{resize}
	
	\item \verb|cv2.GaussianBlur|: es un filtro que suaviza la definición de la imagen a través de un kernel Gaussiano. El filtrado gaussiano se realiza convolucionando cada punto de la matriz de entrada con un núcleo gaussiano y luego sumándolos a todos para producir la matriz de salida. \cite{GaussianBlur}
	
	\item \verb|cv2.cvtColor|: cambia el espacio de color de una imagen digital 
	a otro. \cite{cvTcolor}
	
	\item \verb|cv2.adaptiveThreshold|: el método adaptativetreshold binariza una imagen de acuerdo a un valor de umbral que cálcula para pequeñas regiones de la imagen digital. Así, el filtro gaussiano realiza una convolución con cada punto de la matriz generando una matriz de salida. El valor de umbral es calculado como la suma ponderada de los valores del vecindario donde los pesos son una ventana gaussiana. Las dimesiones del kernel representa el tamaño del vecindario de pixeles usados para calcular el valor umbral. \cite{AdaptTresh}
	
	\item \verb|cv2.dilate()|: Dilate es un método de transformación morfológica. Las operaciones morfológicas aplican un elemento estructurante a la imagen de entrada y generan una de salida con características morfológicas diferentes. Dilate utiliza un kernel \textit{B} el cual se escanea sobre la imagen, calcula el valor máximo de pixeles superpuestos por \textit{B}  y reemplazamos el píxel de la imagen en la posición del punto de anclaje con ese valor máximo. Como se puede deducir, esta operación de maximización hace que las regiones brillantes dentro de una imagen "crezcan". \cite{Dilate}
	
	\item \verb|cv2.findcontours|: definiendo contorno como una curva todos los puntos continuos que tienen el mismo color o intensidad, este método encuentra los contornos definidos en una imagen, preferiblemente binarizada. Este método requiere diferentes parámetros de entrada que definen su modo de funcionamiento como le modo de recuperación de contorno y método de aproximación de contorno. Ambos parámetros son explicados en las fuentes de documentación. \cite{findContours}
	
	\item \verb|cv2.boundingRect|: esta función calcula y devuelve el rectángulo delimitador de un contorno o un conjunto de píxeles de la misma intensidad y distintos de cero. Esta función cálcula un rectangulo recto, es decir, no considera ángulo de rotación por lo tanto el área del rectángulo no será mínima. Esta función devuelve las coordenadas de la esquina superior izquierda del rectángulo, su ancho y alto. \cite{boundRectangle}
	
	\item \verb|cv2.rectangle|: esta función es una de las funciones de dibujo de la librería \textit{OpenCV} y dibuja un rectángulo en la imagen, dadas unas coordenadas específicas, con color y ancho de línea específico. La función devuelve la imagen con dicho polígono dibujado. \cite{rectangle}
	
\end{itemize} 	

\section{Scikit-Learn}

Scikit-Learn por su parte, es una biblioteca con basto desarrollo en los aprendizajes automático de máquina de software libre para el lenguaje de programación Python. Cuenta con varios algoritmos de regresión, clasificación y análisis de grupos como SVMs, bosques aleatorios, K-means, entre otros. Esta biblioteca inició como un proyecto de Google Summer of code por David Cournapeau en el 2007. Para mayor información y detalles acerca de la biblioteca dirigirse a http://scikit-learn.org/stable/.  



